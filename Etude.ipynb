{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des package\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids\n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15634602</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15647311</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15619304</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15701354</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15737888</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  credit_score country  gender  age  tenure    balance  \\\n",
       "0     15634602           619  France  Female   42       2       0.00   \n",
       "1     15647311           608   Spain  Female   41       1   83807.86   \n",
       "2     15619304           502  France  Female   42       8  159660.80   \n",
       "3     15701354           699  France  Female   39       1       0.00   \n",
       "4     15737888           850   Spain  Female   43       2  125510.82   \n",
       "\n",
       "   products_number  credit_card  active_member  estimated_salary  churn  \n",
       "0                1            1              1         101348.88      1  \n",
       "1                1            0              1         112542.58      0  \n",
       "2                3            1              0         113931.57      1  \n",
       "3                2            0              0          93826.63      0  \n",
       "4                1            1              1          79084.10      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture du CSV\n",
    "df = pd.read_csv('churn_train_bank.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customer_id       10000 non-null  int64  \n",
      " 1   credit_score      10000 non-null  int64  \n",
      " 2   country           10000 non-null  object \n",
      " 3   gender            10000 non-null  object \n",
      " 4   age               10000 non-null  int64  \n",
      " 5   tenure            10000 non-null  int64  \n",
      " 6   balance           10000 non-null  float64\n",
      " 7   products_number   10000 non-null  int64  \n",
      " 8   credit_card       10000 non-null  int64  \n",
      " 9   active_member     10000 non-null  int64  \n",
      " 10  estimated_salary  10000 non-null  float64\n",
      " 11  churn             10000 non-null  int64  \n",
      "dtypes: float64(2), int64(8), object(2)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous cherchons à effectuer des prédictions sur les clients en général. Nous pouvons supprimer customer_id et country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['customer_id', 'country'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformation de product_number en type object\n",
    "df.products_number = df['products_number'].astype('object')\n",
    "\n",
    "# Encodage de la variable gender\n",
    "df['gender'] = LabelEncoder().fit_transform(df['gender'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création df des varaibles explicatives\n",
    "feats = df.drop('churn', axis=1)\n",
    "\n",
    "# Cration de la varaible cible\n",
    "target = df['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform products_number en plusieurs variables indicatrices\n",
    "feats = pd.get_dummies(feats, prefix=['products'], prefix_sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création ensemble entrainement et test (75/25%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation des variable continues\n",
    "\n",
    "cols = ['credit_score','age', 'balance', 'estimated_salary']\n",
    "\n",
    "X_train[cols]= StandardScaler().fit_transform(X_train[cols])\n",
    "X_test[cols]= StandardScaler().fit_transform(X_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "0    0.7963\n",
       "1    0.2037\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage distribution target en % \n",
    "target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre base cleints, 20.37% des clients présents ont quitté la banque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur l'ensemble de test 0.8392\n"
     ]
    }
   ],
   "source": [
    "# Création modèle classification SVM \n",
    "svm = SVC(gamma='scale')\n",
    "\n",
    "# Entrainement sur ensemble train\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Score\n",
    "print('Score sur l\\'ensemble de test', svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre modèle obtient 83% des bonnes prédictions. \n",
    "\n",
    "Notre objectif est de prédire les départs éventuels des cleints. Est-ce que le résultat signifie que sur 10 clients churners 8 seront identifiées comme tel ? Non. \n",
    "\n",
    "Pour réussir à détecter le comportement naïf d’un modèle, l’outil le plus efficace est toujours la matrice de confusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predictions</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>385</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predictions     0    1\n",
       "churn                 \n",
       "0            1984   17\n",
       "1             385  114"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prédiction sur le modèle test\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Matrice de confusion\n",
    "\n",
    "pd.crosstab(y_test, y_pred, colnames=['Predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la matrice de confusion nous indique que le bon taux de bonnes prédictions obtenu est largement influencé par le bon comportement du modèle sur la classe dominante (0).\n",
    "\n",
    "Le F1-score permet de mesurer la précision et le rappel à la fois.\n",
    "\n",
    "\n",
    "Dans le cas d'une classification binaire, la sensibilité et la spécificité correspondent respectivement aux rappels de la classe positive et de la classe négative.\n",
    "\n",
    "\n",
    "Une autre métrique, la moyenne géometrique (geometric mean), s'avère utile pour les problèmes de classification déséquilibrée : il s'agit de la racine du produit de la sensibilité et de la spécificité.\n",
    "\n",
    "\n",
    "La fonction classification_report_imbalanced() permet d'afficher un rapport contenant notamment les résultats sur l'ensemble des métriques du package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.84      0.99      0.23      0.91      0.48      0.24      2001\n",
      "          1       0.87      0.23      0.99      0.36      0.48      0.21       499\n",
      "\n",
      "avg / total       0.84      0.84      0.38      0.80      0.48      0.24      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Affichage rapport évlutaion du modèle sur test\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le tableau montre que le rappel et le f1-score de la classe 1 sont mauvais, tandis que pour la class 0, ils sont élevés. La moyenne géométrique est également faible. Le modèle n'est donc pas acceptable pour notre problème. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'oversampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Des méthodes dites de rééchantillonnage permettent de modifier les données avant d’entraîner le modèle dessus. Ces méthodes se divisent en 2 groupes principaux : les méthodes de sur-échantillonnage (Oversampling) et de sous-échantillonnage (Undersampling)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons aborder l'Oversampling aléatoire et le SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de nouveau ensemble de donnée à partir de x et y train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes échantillon oversampled: {0: 5962, 1: 5962}\n"
     ]
    }
   ],
   "source": [
    "#-> Oversampling aléatoire\n",
    "X_ro, y_ro = RandomOverSampler().fit_resample(X_train, y_train)\n",
    "\n",
    "# Affichage nb élément\n",
    "print('Classes échantillon oversampled:', dict(pd.Series(y_ro).value_counts()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes échantillon SMOTE : {0: 5962, 1: 5962}\n"
     ]
    }
   ],
   "source": [
    "#-> SMOTE\n",
    "X_sm, y_sm = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "# Affichage nb élément\n",
    "print('Classes échantillon SMOTE :', dict(pd.Series(y_sm).value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement le modèle sur l'ensemble issu du RandomOversampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1547</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0    1\n",
       "churn           \n",
       "0      1547  454\n",
       "1       124  375"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création modèle class SVM\n",
    "svm = SVC(gamma='scale')\n",
    "\n",
    "#Entrainement du modèle\n",
    "svm.fit(X_ro, y_ro)\n",
    "\n",
    "# Prédiction\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Matrice de confusion\n",
    "pd.crosstab(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.93      0.77      0.75      0.84      0.76      0.58      2001\n",
      "          1       0.45      0.75      0.77      0.56      0.76      0.58       499\n",
      "\n",
      "avg / total       0.83      0.77      0.76      0.79      0.76      0.58      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La geometric mean est plus élévé. Le f1 est déjà meilleur que sur l’entrainement précédent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement le modèle sur l'ensemble issu du SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1573</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0    1\n",
       "churn           \n",
       "0      1573  428\n",
       "1       141  358"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création modèle class SVM\n",
    "svm = SVC(gamma='scale')\n",
    "\n",
    "#Entrainement du modèle\n",
    "svm.fit(X_sm, y_sm)\n",
    "\n",
    "# Prédiction\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Matrice de confusion\n",
    "pd.crosstab(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.92      0.79      0.72      0.85      0.75      0.57      2001\n",
      "          1       0.46      0.72      0.79      0.56      0.75      0.56       499\n",
      "\n",
      "avg / total       0.83      0.77      0.73      0.79      0.75      0.57      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'entrainement le plus qualitaif est l'entrainement du modèle sur l'ensemble issu du RandomOversampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les méthodes d'Undersampling fonctionnent en diminuant le nombre d'observations de la / des classes majoritaires afin d'arriver à un ratio classe minoritaire / classe majoritaire satisfaisant.\n",
    "Elles fonctionnent par sélection ou génération d'échantillons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes échantillon undersampled : {0: 1538, 1: 1538}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarah\\miniconda3\\envs\\projetct\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes échantillon CC : {0: 1538, 1: 1538}\n"
     ]
    }
   ],
   "source": [
    "#Random Undersampling\n",
    "rUs = RandomUnderSampler()\n",
    "X_ru, y_ru = rUs.fit_resample(X_train, y_train)\n",
    "print('Classes échantillon undersampled :', dict(pd.Series(y_ru).value_counts()))\n",
    "\n",
    "#Centroids\n",
    "cc = ClusterCentroids()\n",
    "X_cc, y_cc = cc.fit_resample(X_train, y_train)\n",
    "print('Classes échantillon CC :', dict(pd.Series(y_cc).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0     0    1\n",
      "churn           \n",
      "0      1469  532\n",
      "1       115  384\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.93      0.73      0.77      0.82      0.75      0.56      2001\n",
      "          1       0.42      0.77      0.73      0.54      0.75      0.57       499\n",
      "\n",
      "avg / total       0.83      0.74      0.76      0.76      0.75      0.56      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='scale')\n",
    "svm.fit(X_ru, y_ru)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "print(pd.crosstab(y_test, y_pred))\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0     0    1\n",
      "churn           \n",
      "0      1208  793\n",
      "1        96  403\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.93      0.60      0.81      0.73      0.70      0.48      2001\n",
      "          1       0.34      0.81      0.60      0.48      0.70      0.50       499\n",
      "\n",
      "avg / total       0.81      0.64      0.77      0.68      0.70      0.48      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='scale')\n",
    "svm.fit(X_cc, y_cc)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "print(pd.crosstab(y_test, y_pred))\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutes les méthodes appliquées ici donnent de meilleurs résultats que ceux obtenus par l'ensemble d'entraînement original.\n",
    "Cependant, on peut remarquer qu'avec des résultats quasi identiques, les méthodes d'Undersampling permettent aux modèles d'être entraîné sur un échantillon de taille très réduite (environ quatre fois moins d'observations), ce qui se révèle utile pour de grosse bases de données.\n",
    "Parfois, les méthodes de ré-échantillonnage ne sont pas assez efficaces, et dans ce cas il convient de repenser le problème.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autre méthode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "il suffit d'ajouter dans notre modèle SVM par exemple l'argument probability=True, et d'utiliser la fonction predict_proba afin de retourner les probabilités d'appartenir à chacune des classes, au lieu de la classe la plus probable.\n",
    "\n",
    "\n",
    "Si la probabilité d'appartenir à la classe 1 est supérieur au seuil défini, le client sera considéré comme un potentiel churner. Plus le seuil est bas, plus la précision augmentera, mais le rappel diminuera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1478</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0    1\n",
       "churn           \n",
       "0      1478  523\n",
       "1       118  381"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(probability=True, gamma='scale') # 'probability= True' est nécessaire pour retourner les probas\n",
    "svm.fit(X_ru, y_ru)                        # mais ralentit l'entraînement\n",
    "\n",
    "threshold = 0.5 # Tester avec 0.4, 0.6, ...\n",
    "\n",
    "probs = svm.predict_proba(X_test)\n",
    "pred_class = (probs[:,1]>=threshold).astype('int')\n",
    "\n",
    "pd.crosstab(y_test, pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1300</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0    1\n",
       "churn           \n",
       "0      1300  701\n",
       "1        79  420"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(probability=True, gamma='scale') # 'probability= True' est nécessaire pour retourner les probas\n",
    "svm.fit(X_ru, y_ru)                        # mais ralentit l'entraînement\n",
    "\n",
    "threshold = 0.4 \n",
    "\n",
    "probs = svm.predict_proba(X_test)\n",
    "pred_class = (probs[:,1]>=threshold).astype('int')\n",
    "\n",
    "pd.crosstab(y_test, pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1630</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0    1\n",
       "churn           \n",
       "0      1630  371\n",
       "1       154  345"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(probability=True, gamma='scale') # 'probability= True' est nécessaire pour retourner les probas\n",
    "svm.fit(X_ru, y_ru)                        # mais ralentit l'entraînement\n",
    "\n",
    "threshold = 0.6 \n",
    "\n",
    "probs = svm.predict_proba(X_test)\n",
    "pred_class = (probs[:,1]>=threshold).astype('int')\n",
    "\n",
    "pd.crosstab(y_test, pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre solution, plus facile, mais pas moins efficace dans certains cas est simplement d'utiliser le paramètre class_weight disponible dans la plupart des classes d'algorithmes de scikit-learn.\n",
    "\n",
    "\n",
    "Il permet de pénaliser les erreurs faites sur une classe par un nouveau poids. Plus le poids d'une classe est important, plus les erreurs sur cette classe sont pénalisées, et plus on lui donne de l'importance.\n",
    "\n",
    "\n",
    "Les poids doivent être indiqués sous forme de dictionnaire, par exemple : {0: 1, 1: 5}, pour donner 5 fois plus de poids aux erreurs faites sur la classe 1.\n",
    "L'argument 'balanced' permet d'associer à chaque classe un poids inversement proportionnel à sa fréquence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1509</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0    1\n",
       "churn           \n",
       "0      1509  492\n",
       "1       119  380"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(gamma='scale', class_weight='balanced')\n",
    "svm.fit(X_train, y_train)                         \n",
    "\n",
    "preds = svm.predict(X_test)\n",
    "\n",
    "pd.crosstab(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une dernière solution proposée par le sous-package imblearn.ensemble, est l'utilisation de classes contenant des modèles d'ensembles comme le Boosting ou Bagging et entraînés à chaque étape de l'algorithme sur un échantillon rééquilibré automatiquement entre les différentes classes.\n",
    "\n",
    "\n",
    "Ces implémentations de modèles permettent de se passer de méthode de ré-échantillonnage avant l'entraînement, et de les appliquer de manière automatique à chaque sélection de données par l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarah\\miniconda3\\envs\\projetct\\Lib\\site-packages\\imblearn\\ensemble\\_forest.py:546: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "c:\\Users\\sarah\\miniconda3\\envs\\projetct\\Lib\\site-packages\\imblearn\\ensemble\\_forest.py:558: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1568</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0    1\n",
       "churn           \n",
       "0      1568  433\n",
       "1       120  379"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "bclf = BalancedRandomForestClassifier()\n",
    "bclf.fit(X_train, y_train) \n",
    "y_pred = bclf.predict(X_test)\n",
    "pd.crosstab(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous nos modèles entraînés donnent de meilleurs résultats que ceux utilisant les ensembles de données initiaux.\n",
    "\n",
    "\n",
    "Les méthodes vues s'appuient sur des procédés qui peuvent donner des résultats différents en fonction du type de données à notre disposition et de l'objectif poursuivi.\n",
    "\n",
    "\n",
    "Il est important de retenir que plus le déséquilibre entre les classes est grand, moins les modèles classiques réussiront à prédire la classe minoritaire.\n",
    "\n",
    "\n",
    "Dans de nombreux cas, les données réelles sont concernées par un problème de déséquilibre, il faudra donc nécessairement utiliser voire combiner certaines des méthodes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projetct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
